{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import math\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = ['sno','reviewerID','asin','reviewerName','helpful__001','helpful__002','reviewText','overall','summary','unixReviewTime','reviewTime','label','rating']\n",
    "df = pd.read_csv(\"lreviews.csv\",header=None, names=cols)\n",
    "#print(df)\n",
    "# above line will be different depending on where you saved your data, and your file name\n",
    "#df.head()\n",
    "df.drop(['sno','reviewerID','asin','reviewerName','helpful__001','helpful__002','overall','summary','unixReviewTime','reviewTime','label'],axis=1,inplace=True)\n",
    "#print(df)\n",
    "'''\n",
    "data_dict = {\n",
    "    'rating':{\n",
    "        'type':df.rating.dtype,\n",
    "        'description':'rating class - 0:negative, 1:positive'\n",
    "    },\n",
    "    'reviewText':{\n",
    "        'type':df.reviewText.dtype,\n",
    "        'description':'review text'\n",
    "    },\n",
    "   \n",
    "    'pre_clean_len':{\n",
    "        'type':df.pre_clean_len.dtype,\n",
    "        'description':'Length of the tweet before cleaning'\n",
    "    },\n",
    "    'dataset_shape':df.shape\n",
    "}'''\n",
    "\n",
    "\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "class Splitter(object):\n",
    "    def __init__(self):\n",
    "        self.nltk_splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        self.nltk_tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    def split(self, text):\n",
    "        sentences = self.nltk_splitter.tokenize(text)\n",
    "        tokenized_sentences = [self.nltk_tokenizer.tokenize(sent) for sent in sentences]\n",
    "        return tokenized_sentences\n",
    "class POSTagger(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def pos_tag(self, sentences):\n",
    "        pos = [nltk.pos_tag(sentence) for sentence in sentences]\n",
    "        pos = [[(word, word, [postag]) for (word, postag) in sentence] for sentence in pos]\n",
    "        return pos\n",
    "    \n",
    "    \n",
    "    \n",
    "splitter = Splitter()\n",
    "tok = WordPunctTokenizer()\n",
    "postagger = POSTagger()\n",
    "def review_cleaner(text):\n",
    "    lower_case=\"\"\n",
    "    for i in range(0,len(text)):\n",
    "        if text[i].isalpha():\n",
    "            lower_case=lower_case+text[i].lower()\n",
    "        elif text[i].isdigit():\n",
    "            lower_case=lower_case\n",
    "        else:\n",
    "            lower_case=lower_case+text[i]\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    forpos= \" \".join(words).strip()\n",
    "    splitted_sentences = splitter.split(forpos)\n",
    "    pos_tagged_sentences = postagger.pos_tag(splitted_sentences)\n",
    "    altered_text=\"\"\n",
    "    for sentences in pos_tagged_sentences:\n",
    "        for word in sentences:\n",
    "            v=word[2]\n",
    "            for val in v:\n",
    "                if (val==\"JJ\" or val==\"JJR\" or val==\"JJS\" or val==\"VB\" or val==\"VBD\" or val==\"VBG\"\n",
    "                    or val==\"VBN\" or val==\"VBP\" or val==\"VBZ\" or val==\"RB\" or val==\"RBR\" or val==\"RBS\" ):\n",
    "                    altered_text=altered_text+word[0]+\" \"\n",
    "    return altered_text\n",
    "\n",
    "clean_review_texts = np.empty([1, 2], dtype=object)\n",
    "for i in range(0,6000):      \n",
    "    clean_review_texts=np.append(clean_review_texts, np.array([[review_cleaner(df.iloc[i]['reviewText']),df.iloc[i]['rating']]]), axis=0)\n",
    "clean_review_texts=np.delete(clean_review_texts, 0, 0)\n",
    "clean_df = pd.DataFrame(clean_review_texts,columns=['text','target'])    \n",
    "clean_df.to_csv('lclean_review.csv',encoding='utf-8')\n",
    "my_df = pd.read_csv('lclean_review.csv',index_col=0)\n",
    "\n",
    "'''\n",
    "neg_tweets = my_df[my_df.target == 0]\n",
    "neg_string = []\n",
    "for t in neg_tweets.text:\n",
    "    neg_string.append(t)\n",
    "neg_string = pd.Series(neg_string).str.cat(sep=' ')\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(width=1600, height=800,max_font_size=200).generate(neg_string)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "neu_tweets = my_df[my_df.target == 4]\n",
    "neu_string = []\n",
    "for t in neu_tweets.text:\n",
    "    neu_string.append(t)\n",
    "neu_string = pd.Series(neu_string).str.cat(sep=' ')\n",
    "wordcloud = WordCloud(width=1600, height=800,max_font_size=200,colormap='magma').generate(neu_string)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "pos_tweets = my_df[my_df.target == 4]\n",
    "pos_string = []\n",
    "for t in pos_tweets.text:\n",
    "    pos_string.append(t)\n",
    "pos_string = pd.Series(pos_string).str.cat(sep=' ')\n",
    "wordcloud = WordCloud(width=1600, height=800,max_font_size=200,colormap='magma').generate(pos_string)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(dtype='float32')\n",
    "cvec.fit(my_df.text)\n",
    "print(len(cvec.get_feature_names()))\n",
    "\n",
    "neg_doc_matrix = cvec.transform(my_df[my_df.target == 0].text)\n",
    "neu_doc_matrix = cvec.transform(my_df[my_df.target == 2].text)\n",
    "pos_doc_matrix = cvec.transform(my_df[my_df.target == 4].text)\n",
    "neg_tf = np.sum(neg_doc_matrix,axis=0)\n",
    "neu_tf = np.sum(neu_doc_matrix,axis=0)\n",
    "pos_tf = np.sum(pos_doc_matrix,axis=0)\n",
    "neg = np.squeeze(np.asarray((neg_tf)))\n",
    "neu = np.squeeze(np.asarray((neu_tf)))\n",
    "pos = np.squeeze(np.asarray((pos_tf)))\n",
    "\n",
    "\n",
    "\n",
    "term_freq_df = pd.DataFrame([neg,neu,pos],columns=cvec.get_feature_names()).transpose()\n",
    "term_freq_df.head()\n",
    "term_freq_df.columns = ['negative','neutral', 'positive']\n",
    "term_freq_df['total'] = term_freq_df['negative'] + term_freq_df['neutral'] +term_freq_df['positive']\n",
    "#term_freq_df.sort_values(by='total', ascending=False).iloc[:10]\n",
    "#document_matrix = cvec.transform(my_df.text)\n",
    "\n",
    "term_freq_df.to_csv('lterm_freq_df.csv',encoding='utf-8')\n",
    "term_freq_tfidf = pd.read_csv('lterm_freq_df.csv',index_col=0)\n",
    "#print(term_freq_tfidf)\n",
    "term_freq_tfidff = pd.DataFrame([neg,neu,pos],columns=cvec.get_feature_names()).transpose()\n",
    "term_freq_tfidff.columns = ['negative','neutral', 'positive']\n",
    "for i in range(0,7227):\n",
    "    tot=term_freq_tfidf.iloc[i]['total']\n",
    "    nn=term_freq_tfidf.iloc[i]['negative']\n",
    "    nu=term_freq_tfidf.iloc[i]['neutral']\n",
    "    ps=term_freq_tfidf.iloc[i]['positive']\n",
    "    if nn==0:\n",
    "        term_freq_tfidff.iloc[i]['negative']=0\n",
    "    elif nn==tot:\n",
    "        term_freq_tfidff.iloc[i]['negative']=2*nn\n",
    "    else:\n",
    "        term_freq_tfidff.iloc[i]['negative']=1/(math.log((tot/nn),10))\n",
    "    if nu==0:\n",
    "        term_freq_tfidff.iloc[i]['neutral']=0\n",
    "    elif nu==tot:\n",
    "        term_freq_tfidff.iloc[i]['neutral']=2*nu\n",
    "    else:\n",
    "        term_freq_tfidff.iloc[i]['neutral']=1/(math.log((tot/nu),10))\n",
    "    if ps==0:\n",
    "        term_freq_tfidff.iloc[i]['positive']=0\n",
    "    elif ps==tot:\n",
    "        term_freq_tfidff.iloc[i]['positive']=2*ps\n",
    "    else:\n",
    "        term_freq_tfidff.iloc[i]['positive']=1/(math.log((tot/ps),10))\n",
    "        #print(1/(math.log((tot/ps),10)))\n",
    "        #print(float(term_freq_tfidff.iloc[i]['positive']))\n",
    "term_freq_tfidff.to_csv('lterm_freq_tfidff.csv',encoding='utf-8') \n",
    "createfeed=pd.read_csv('lterm_freq_tfidff.csv',index_col=0)\n",
    "columns=[\"Sno\",\"freq_neg\",\"freq_neutral\",\"freq_pos\",\"overall\"]\n",
    "with open('lsixthousandfeed.csv','w') as myfile:\n",
    "    wr = csv.writer(myfile,quoting=csv.QUOTE_NONE)\n",
    "    wr.writerow(columns)\n",
    "    for i in range(0,6000):\n",
    "        feature_values=[0,0,0]\n",
    "        text_for_comparison = my_df.iloc[i]['text']\n",
    "        words= text_for_comparison.split()\n",
    "        for j in range(0,len(words)):\n",
    "            feature_values = np.add(feature_values,[createfeed.loc[words[j]][0],createfeed.loc[words[j]][1],createfeed.loc[words[j]][2]])\n",
    "        feature_values = feature_values.tolist()\n",
    "        feature_values.insert(0, i)\n",
    "        new_lab=my_df.iloc[i]['target']\n",
    "        feature_values.insert(4, new_lab)\n",
    "        wr.writerow(feature_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
